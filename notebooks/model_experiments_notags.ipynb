{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.286111Z",
     "start_time": "2025-09-22T10:00:46.283935Z"
    }
   },
   "source": [
    "import torch\n",
    "from config.paths import MODEL_PATHS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7b7ecbabe507e744"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.433719Z",
     "start_time": "2025-09-22T10:00:46.297421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from config.paths import TAG_FILED_DATA_PATH\n",
    "\n",
    "X_target_list = []\n",
    "\n",
    "for file in os.listdir(TAG_FILED_DATA_PATH):\n",
    "    if file.endswith(\".mat\"):\n",
    "        mat_data = loadmat(os.path.join(TAG_FILED_DATA_PATH, file))\n",
    "        print(file, mat_data.keys())\n",
    "\n",
    "        # 获取除 __header__, __version__, __globals__ 外的键\n",
    "        data_keys = [k for k in mat_data.keys() if not k.startswith('__')]\n",
    "        if len(data_keys) != 1:\n",
    "            raise ValueError(f\"文件 {file} 中信号键不唯一: {data_keys}\")\n",
    "        signal_key = data_keys[0]\n",
    "\n",
    "        # 读取信号\n",
    "        signal = mat_data[signal_key]\n",
    "        X_target_list.append(signal)\n",
    "\n",
    "# 拼接成一个大数组\n",
    "X_target_raw = np.vstack(X_target_list)\n",
    "print(\"目标域数据 shape:\", X_target_raw.shape)\n"
   ],
   "id": "81e117d339178d4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.mat dict_keys(['__header__', '__version__', '__globals__', 'A'])\n",
      "B.mat dict_keys(['__header__', '__version__', '__globals__', 'B'])\n",
      "C.mat dict_keys(['__header__', '__version__', '__globals__', 'C'])\n",
      "D.mat dict_keys(['__header__', '__version__', '__globals__', 'D'])\n",
      "E.mat dict_keys(['__header__', '__version__', '__globals__', 'E'])\n",
      "F.mat dict_keys(['__header__', '__version__', '__globals__', 'F'])\n",
      "G.mat dict_keys(['__header__', '__version__', '__globals__', 'G'])\n",
      "H.mat dict_keys(['__header__', '__version__', '__globals__', 'H'])\n",
      "I.mat dict_keys(['__header__', '__version__', '__globals__', 'I'])\n",
      "J.mat dict_keys(['__header__', '__version__', '__globals__', 'J'])\n",
      "K.mat dict_keys(['__header__', '__version__', '__globals__', 'K'])\n",
      "L.mat dict_keys(['__header__', '__version__', '__globals__', 'L'])\n",
      "M.mat dict_keys(['__header__', '__version__', '__globals__', 'M'])\n",
      "N.mat dict_keys(['__header__', '__version__', '__globals__', 'N'])\n",
      "O.mat dict_keys(['__header__', '__version__', '__globals__', 'O'])\n",
      "P.mat dict_keys(['__header__', '__version__', '__globals__', 'P'])\n",
      "目标域数据 shape: (4096000, 1)\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.669647Z",
     "start_time": "2025-09-22T10:00:46.467573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 无标签\n",
    "X_train_tgt, X_test_tgt = train_test_split(X_target_raw, test_size=0.2, random_state=42)\n",
    "X_train_tgt, X_val_tgt = train_test_split(X_train_tgt, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"训练集:\", X_train_tgt.shape)\n",
    "print(\"验证集:\", X_val_tgt.shape)\n",
    "print(\"测试集:\", X_test_tgt.shape)\n"
   ],
   "id": "cb3736f50218e395",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (2621440, 1)\n",
      "验证集: (655360, 1)\n",
      "测试集: (819200, 1)\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.719491Z",
     "start_time": "2025-09-22T10:00:46.702981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "TARGET_PICKLE_PATHS = r\"E:/python_file/TransBearingDiag/src/data/target/processed\"\n",
    "\n",
    "save_file = os.path.join(TARGET_PICKLE_PATHS, \"target_data.pkl\")\n",
    "# 保存目标域数据\n",
    "joblib.dump([X_train_tgt, X_val_tgt, X_test_tgt], save_file)\n",
    "print(\"目标域数据已保存:\", save_file)\n"
   ],
   "id": "5cce1891a0a794c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标域数据已保存: E:/python_file/TransBearingDiag/src/data/target/processed\\target_data.pkl\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "859971e6a4d1b161"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.805952Z",
     "start_time": "2025-09-22T10:00:46.779262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_signal(data, frame_len=128, step=64):\n",
    "    frames = []\n",
    "    for i in range(0, len(data) - frame_len + 1, step):\n",
    "        frames.append(data[i:i+frame_len, 0])\n",
    "    return np.array(frames)\n",
    "\n",
    "frame_len = 128\n",
    "step = 64\n",
    "X_train_tgt_frames = split_signal(X_train_tgt, frame_len=frame_len, step=step)\n",
    "X_val_tgt_frames   = split_signal(X_val_tgt, frame_len=frame_len, step=step)\n",
    "X_test_tgt_frames  = split_signal(X_test_tgt, frame_len=frame_len, step=step)\n",
    "print(\"分帧后目标域训练集:\", X_train_tgt_frames.shape)"
   ],
   "id": "f9e112565d4cc506",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分帧后目标域训练集: (40959, 128)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.813577Z",
     "start_time": "2025-09-22T10:00:46.808669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TargetDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_loader_tgt = DataLoader(TargetDataset(X_train_tgt_frames), batch_size=batch_size, shuffle=True)\n",
    "val_loader_tgt   = DataLoader(TargetDataset(X_val_tgt_frames), batch_size=batch_size, shuffle=False)\n",
    "test_loader_tgt  = DataLoader(TargetDataset(X_test_tgt_frames), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"目标域 DataLoader 已创建\")"
   ],
   "id": "84c12aea1b64642e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标域 DataLoader 已创建\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.846739Z",
     "start_time": "2025-09-22T10:00:46.844009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "split_file = os.path.join(MODEL_PATHS, \"train_val_test_split.pkl\")\n",
    "X_train_src, X_val_src, X_test_src, y_train_src, y_val_src, y_test_src = joblib.load(split_file)\n",
    "\n",
    "# 标签编码\n",
    "if isinstance(y_train_src, np.ndarray) and (y_train_src.dtype=='O' or y_train_src.dtype.type is np.str_):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_src = label_encoder.fit_transform(y_train_src)\n",
    "    y_val_src   = label_encoder.transform(y_val_src)\n",
    "    y_test_src  = label_encoder.transform(y_test_src)\n",
    "\n",
    "y_train_src = torch.tensor(y_train_src, dtype=torch.long)\n",
    "y_val_src   = torch.tensor(y_val_src, dtype=torch.long)\n",
    "y_test_src  = torch.tensor(y_test_src, dtype=torch.long)"
   ],
   "id": "8d149f157ee16fe9",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.891539Z",
     "start_time": "2025-09-22T10:00:46.878924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    X_train_tgt, X_val_tgt, X_test_tgt = joblib.load(os.path.join(TARGET_PICKLE_PATHS, \"target_data.pkl\"))\n",
    "    y_train_tgt = y_val_tgt = y_test_tgt = None\n",
    "    print(\"目标域数据加载完成，无标签\")\n",
    "except:\n",
    "    X_train_tgt = X_val_tgt = X_test_tgt = None\n",
    "    print(\"未找到目标域数据\")\n"
   ],
   "id": "6d24884ad9ede605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目标域数据加载完成，无标签\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7a30c2b1b772dba9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.928484Z",
     "start_time": "2025-09-22T10:00:46.924929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 处理源域标签\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "if 'y_train_src' not in globals():\n",
    "    split_file = os.path.join(MODEL_PATHS, \"train_val_test_split.pkl\")\n",
    "    X_train_src, X_val_src, X_test_src, y_train_src, y_val_src, y_test_src = joblib.load(split_file)\n",
    "\n",
    "# 如果 y_train_src 是 numpy array\n",
    "if isinstance(y_train_src, np.ndarray):\n",
    "    if y_train_src.dtype == 'O' or y_train_src.dtype.type is np.str_:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_src = label_encoder.fit_transform(y_train_src)\n",
    "        y_val_src   = label_encoder.transform(y_val_src)\n",
    "        y_test_src  = label_encoder.transform(y_test_src)\n",
    "        print(\"源域类别映射：\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "elif isinstance(y_train_src, torch.Tensor):\n",
    "    # 先转换为 numpy，再处理\n",
    "    y_train_src_np = y_train_src.cpu().numpy()\n",
    "    y_val_src_np   = y_val_src.cpu().numpy()\n",
    "    y_test_src_np  = y_test_src.cpu().numpy()\n",
    "\n",
    "    if y_train_src_np.dtype == 'O' or y_train_src_np.dtype.type is np.str_:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_src_np = label_encoder.fit_transform(y_train_src_np)\n",
    "        y_val_src_np   = label_encoder.transform(y_val_src_np)\n",
    "        y_test_src_np  = label_encoder.transform(y_test_src_np)\n",
    "        print(\"源域类别映射：\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "    # 转回 torch.Tensor\n",
    "    y_train_src = torch.tensor(y_train_src_np, dtype=torch.long)\n",
    "    y_val_src   = torch.tensor(y_val_src_np, dtype=torch.long)\n",
    "    y_test_src  = torch.tensor(y_test_src_np, dtype=torch.long)\n",
    "\n",
    "# 转Tensor\n",
    "else:\n",
    "    y_train_src = torch.tensor(y_train_src, dtype=torch.long)\n",
    "    y_val_src   = torch.tensor(y_val_src, dtype=torch.long)\n",
    "    y_test_src  = torch.tensor(y_test_src, dtype=torch.long)\n",
    "#源域数据 shape\n",
    "print(\"源域训练集:\", X_train_src.shape)\n",
    "print(\"源域验证集:\", X_val_src.shape)\n",
    "print(\"源域测试集:\", X_test_src.shape)\n",
    "\n",
    "# 目标域数据 shape\n",
    "if 'X_train_tgt' in globals() and X_train_tgt is not None:\n",
    "    print(\"目标域训练集:\", X_train_tgt.shape)\n",
    "    print(\"目标域验证集:\", X_val_tgt.shape)\n",
    "    print(\"目标域测试集:\", X_test_tgt.shape)\n",
    "else:\n",
    "    print(\"目标域数据不存在，DataLoader 未创建\")\n"
   ],
   "id": "36cc7aac3dddae93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源域训练集: (96, 19)\n",
      "源域验证集: (32, 19)\n",
      "源域测试集: (33, 19)\n",
      "目标域训练集: (2621440, 1)\n",
      "目标域验证集: (655360, 1)\n",
      "目标域测试集: (819200, 1)\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "83ae001c296cb20d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.963193Z",
     "start_time": "2025-09-22T10:00:46.957636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # 动态计算卷积输出\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, input_dim)\n",
    "            x = self.conv_layers(x)\n",
    "            self._to_linear = x.numel()\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train_tgt_frames.shape[1]\n",
    "num_classes = len(torch.unique(y_train_src))\n",
    "model_tgt = CNN1D(input_dim, num_classes)\n"
   ],
   "id": "f21068328c939c2b",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:46.997047Z",
     "start_time": "2025-09-22T10:00:46.991524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_tgt = CNN1D(input_dim, num_classes)\n",
    "src_model_path = os.path.join(MODEL_PATHS, \"model_src.pth\")\n",
    "pretrained_dict = torch.load(src_model_path, map_location='cpu')\n",
    "# 保留卷积层权重\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv_layers\" in k}\n",
    "model_dict = model_tgt.state_dict()\n",
    "model_dict.update(pretrained_dict)\n",
    "model_tgt.load_state_dict(model_dict)"
   ],
   "id": "6307310dde4c262a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c6d43115373d523"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:47.030255Z",
     "start_time": "2025-09-22T10:00:47.026276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_model_path = os.path.join(MODEL_PATHS, \"model_src.pth\")\n",
    "pretrained_dict = torch.load(src_model_path, map_location='cpu')\n",
    "model_dict = model_tgt.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv_layers\" in k and k in model_dict}\n",
    "model_dict.update(pretrained_dict)\n",
    "model_tgt.load_state_dict(model_dict)\n",
    "\n",
    "for param in model_tgt.conv_layers.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_tgt.to(device)"
   ],
   "id": "f40f81bf2759808f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN1D(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e026f75bf43c49b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:47.061208Z",
     "start_time": "2025-09-22T10:00:47.059687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for param in model_tgt.conv_layers.parameters():\n",
    "#     param.requires_grad = False\n",
    "#\n",
    "# model_tgt.to(device)"
   ],
   "id": "b9daa00bd658abd6",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:47.093882Z",
     "start_time": "2025-09-22T10:00:47.091318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "def train_target_model(model, train_loader, num_epochs=5, lr=1e-3):\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        for X in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            X = X.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)  # [batch, num_classes]\n",
    "            loss = torch.mean(outputs ** 2)  # L2 自监督\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "        print(f\"Epoch {epoch + 1}, Avg Loss: {running_loss / len(train_loader.dataset):.6f}\")\n",
    "    return model"
   ],
   "id": "7f95fa6451020263",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a47955638743375c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:50.764878Z",
     "start_time": "2025-09-22T10:00:47.124086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 5\n",
    "model_tgt = train_target_model(model_tgt, train_loader_tgt, num_epochs=num_epochs, lr=1e-3)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model_tgt.state_dict(), os.path.join(MODEL_PATHS, \"model_tgt_notags.pth\"))\n",
    "torch.save(model_tgt, os.path.join(MODEL_PATHS, \"full_model_tgt_notags.pth\"))\n",
    "print(\"目标域模型已保存\")"
   ],
   "id": "43669e498915c2ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 640/640 [00:00<00:00, 824.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 1.745627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 640/640 [00:00<00:00, 930.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 0.000561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 640/640 [00:00<00:00, 904.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 0.000028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 640/640 [00:00<00:00, 892.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 640/640 [00:00<00:00, 865.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 0.000000\n",
      "目标域模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:00:51.018819Z",
     "start_time": "2025-09-22T10:00:50.929943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_tgt.eval()\n",
    "for X in test_loader_tgt:\n",
    "    X = X.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_tgt(X)\n",
    "    print(y_pred.shape)\n"
   ],
   "id": "6e24a6846ec524b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([64, 4])\n",
      "torch.Size([63, 4])\n"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
